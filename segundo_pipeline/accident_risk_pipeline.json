{
  "components": {
    "comp-evaluate-model": {
      "executorLabel": "exec-evaluate-model",
      "inputDefinitions": {
        "artifacts": {
          "X_val_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "model_input": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "y_val_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "eval_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "predictions_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-load-train-data": {
      "executorLabel": "exec-load-train-data",
      "inputDefinitions": {
        "parameters": {
          "train_path": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "train_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-preprocess-encode": {
      "executorLabel": "exec-preprocess-encode",
      "inputDefinitions": {
        "artifacts": {
          "train_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "X_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "encoders_json": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          },
          "y_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-register-model-in-registry": {
      "executorLabel": "exec-register-model-in-registry",
      "inputDefinitions": {
        "artifacts": {
          "eval_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "model_input": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "model_display_name": {
            "parameterType": "STRING"
          },
          "project_id": {
            "parameterType": "STRING"
          },
          "project_location": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-train-model": {
      "executorLabel": "exec-train-model",
      "inputDefinitions": {
        "artifacts": {
          "X_train_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "y_train_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "colsample_bytree": {
            "defaultValue": 0.8,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          },
          "learning_rate": {
            "defaultValue": 0.1,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          },
          "max_depth": {
            "defaultValue": 5.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "n_estimators": {
            "defaultValue": 200.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "random_state": {
            "defaultValue": 42.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "subsample": {
            "defaultValue": 0.8,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "model_output": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "train_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-val-split": {
      "executorLabel": "exec-train-val-split",
      "inputDefinitions": {
        "artifacts": {
          "X_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "y_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "random_state": {
            "defaultValue": 42.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "test_size": {
            "defaultValue": 0.2,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "X_train_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "X_val_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "y_train_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "y_val_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-evaluate-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "evaluate_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pandas' 'xgboost' 'scikit-learn' 'joblib' 'gcsfs'  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef evaluate_model(\n    model_input: Input[Model],\n    X_val_csv: Input[Dataset],\n    y_val_csv: Input[Dataset],\n    eval_metrics: Output[Metrics],      # Alterado de dsl.OutputPath(str)\n    predictions_csv: Output[Dataset],  # Alterado de dsl.OutputPath(str)\n):\n    \"\"\"\n    Avalia um modelo treinado em dados de valida\u00e7\u00e3o.\n    \"\"\"\n    # --- IMPORTA\u00c7\u00d5ES NECESS\u00c1RIAS DENTRO DO COMPONENTE ---\n    import os\n    import json\n    import numpy as np\n    import pandas as pd\n    import joblib\n    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n    try:\n        print(\"Iniciando o componente evaluate_model...\")\n\n        # Carrega o modelo\n        model_load_path = model_input.path + \"/model.joblib\"\n        print(f\"Carregando modelo de: {model_load_path}\")\n        model = joblib.load(model_load_path)\n        print(\"Modelo carregado com sucesso.\")\n\n        # Carrega dados de valida\u00e7\u00e3o\n        print(f\"Lendo X_val de: {X_val_csv.path}\")\n        X_val = pd.read_csv(X_val_csv.path)\n        print(f\"Lendo y_val de: {y_val_csv.path}\")\n        y_val = pd.read_csv(y_val_csv.path).values.ravel()\n        print(\"Dados de valida\u00e7\u00e3o lidos com sucesso.\")\n\n        # Avalia\u00e7\u00e3o\n        print(\"Iniciando predi\u00e7\u00f5es no conjunto de valida\u00e7\u00e3o...\")\n        y_pred = model.predict(X_val)\n        rmse = float(np.sqrt(mean_squared_error(y_val, y_pred)))\n        mae = float(mean_absolute_error(y_val, y_pred))\n        r2 = float(r2_score(y_val, y_pred))\n\n        metrics_data = {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n        print(f\"M\u00e9tricas de avalia\u00e7\u00e3o: {metrics_data}\")\n\n        # Garante que o diret\u00f3rio para o arquivo de m\u00e9tricas exista\n        # Usa .path pois agora \u00e9 um Artefato\n        print(f\"Garantindo que o diret\u00f3rio de m\u00e9tricas exista: {os.path.dirname(eval_metrics.path)}\")\n        os.makedirs(os.path.dirname(eval_metrics.path), exist_ok=True)\n\n        # Usa .path pois agora \u00e9 um Artefato\n        with open(eval_metrics.path, \"w\") as f:\n            json.dump(metrics_data, f, indent=4)\n        print(\"M\u00e9tricas de avalia\u00e7\u00e3o salvas.\")\n\n        # Garante que o diret\u00f3rio para o arquivo de predi\u00e7\u00f5es exista\n        # Usa .path pois agora \u00e9 um Artefato\n        print(f\"Garantindo que o diret\u00f3rio de predi\u00e7\u00f5es exista: {os.path.dirname(predictions_csv.path)}\")\n        os.makedirs(os.path.dirname(predictions_csv.path), exist_ok=True)\n\n        print(f\"Salvando predi\u00e7\u00f5es em: {predictions_csv.path}\")\n        # Usa .path pois agora \u00e9 um Artefato\n        pd.DataFrame({\"y_true\": y_val, \"y_pred\": y_pred}).to_csv(predictions_csv.path, index=False)\n        print(\"Predi\u00e7\u00f5es salvas. Componente evaluate_model conclu\u00eddo.\")\n\n    except Exception as e:\n\n        raise\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-load-train-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "load_train_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pandas' 'gcsfs'  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef load_train_data(\n    train_path: str,\n    train_csv: Output[Dataset]\n):\n    import pandas as pd\n    df = pd.read_csv(train_path)\n    df.to_csv(train_csv.path, index=False)\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-preprocess-encode": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "preprocess_encode"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pandas' 'scikit-learn' 'gcsfs'  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef preprocess_encode(\n    train_csv: Input[Dataset],       # entrada: CSV do componente anterior\n    X_csv: Output[Dataset],          # sa\u00edda: features\n    y_csv: Output[Dataset],          # sa\u00edda: target\n    encoders_json: Output[Artifact]  # sa\u00edda: dicion\u00e1rio dos encoders\n):\n    import pandas as pd\n    from sklearn.preprocessing import LabelEncoder\n    import json\n\n    print(f\"Lendo dataset: {train_csv.path}\")\n    df = pd.read_csv(train_csv.path)\n\n    target = \"accident_risk\"\n    categorical_cols = [\n        \"road_type\", \"lighting\", \"weather\", \"time_of_day\",\n        \"holiday\", \"school_season\", \"public_road\", \"road_signs_present\"\n    ]\n\n    X = df.drop(columns=[target])\n    y = df[[target]]\n\n    encoders = {}\n    for col in categorical_cols:\n        le = LabelEncoder()\n        X[col] = le.fit_transform(X[col].astype(str))\n        encoders[col] = dict(\n            zip(le.classes_.tolist(), le.transform(le.classes_).tolist())\n        )\n\n    print(\"Salvando arquivos de sa\u00edda...\")\n    X.to_csv(X_csv.path, index=False)\n    y.to_csv(y_csv.path, index=False)\n    with open(encoders_json.path, \"w\") as f:\n        json.dump(encoders, f)\n\n    print(\"\u2705 Pr\u00e9-processamento conclu\u00eddo!\")\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-register-model-in-registry": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "register_model_in_registry"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform' 'gcsfs' 'pandas' 'joblib'  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef register_model_in_registry(\n    model_input: Input[Model],\n    eval_metrics: Input[Metrics],\n    project_id: str,\n    project_location: str,\n    model_display_name: str,      # Nome do modelo no Registry (ex: \"accident-risk-model\")\n):\n    \"\"\"\n    Registra um modelo treinado no Vertex AI Model Registry,\n    anexando as m\u00e9tricas de avalia\u00e7\u00e3o como labels.\n    \"\"\"\n\n    # Imports necess\u00e1rios para a *execu\u00e7\u00e3o* do componente (ficam dentro)\n    import json\n    from google.cloud import aiplatform\n\n    try:\n        print(f\"Iniciando o registro do modelo: {model_display_name}\")\n        print(f\"Projeto: {project_id}, Local: {project_location}\")\n\n        # 1. Inicializa o cliente do Vertex AI\n        aiplatform.init(project=project_id, location=project_location)\n\n        # 2. L\u00ea as m\u00e9tricas do arquivo JSON\n        # Usa .path pois agora \u00e9 um Artefato\n        print(f\"Lendo m\u00e9tricas de: {eval_metrics.path}\")\n        with open(eval_metrics.path, \"r\") as f:\n            metrics_data = json.load(f)\n\n        # Converte m\u00e9tricas em 'labels'\n        labels_for_registry = {}\n        for key, value in metrics_data.items():\n            # Garante que a chave seja compat\u00edvel com labels (min\u00fasculas, sem caracteres especiais)\n            safe_key = ''.join(c for c in key.lower() if c.isalnum() or c == '_')\n            # Garante que o valor seja compat\u00edvel (string, substitui '.' por '_')\n            label_value = str(value).replace('.', '_').lower()\n            labels_for_registry[safe_key] = label_value\n\n        print(f\"M\u00e9tricas convertidas para labels: {labels_for_registry}\")\n\n        # 3. Define o cont\u00eainer de predi\u00e7\u00e3o\n        PREBUILT_CONTAINER_URI = \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest\"\n        print(f\"Usando cont\u00eainer de predi\u00e7\u00e3o: {PREBUILT_CONTAINER_URI}\")\n\n        # 4. Faz o upload (registro) do modelo\n        print(f\"Fazendo upload do modelo a partir de: {model_input.path}\")\n\n        registered_model = aiplatform.Model.upload(\n            display_name=model_display_name,\n            artifact_uri=model_input.path,\n            serving_container_image_uri=PREBUILT_CONTAINER_URI,\n            description=f\"Vers\u00e3o registrada via KFP pipeline.\",\n            labels=labels_for_registry\n        )\n\n        print(f\"Modelo registrado com sucesso!\")\n        print(f\"Nome do recurso: {registered_model.resource_name}\")\n        print(f\"Vers\u00e3o: {registered_model.version_id}\")\n\n    except Exception as e:\n        print(f\"Erro ao registrar o modelo: {e}\")\n        raise\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-train-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pandas' 'xgboost' 'scikit-learn' 'joblib' 'gcsfs'  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_model(\n    X_train_csv: Input[Dataset],\n    y_train_csv: Input[Dataset],\n    model_output: Output[Model],\n    train_metrics: Output[Metrics],  # Alterado de dsl.OutputPath(str)\n    n_estimators: int = 200,\n    learning_rate: float = 0.1,\n    max_depth: int = 5,\n    subsample: float = 0.8,\n    colsample_bytree: float = 0.8,\n    random_state: int = 42,\n):\n    \"\"\"\n    Treina um modelo XGBoost Regressor e salva o artefato do modelo\n    e as m\u00e9tricas de treino.\n    \"\"\"\n    # --- IMPORTA\u00c7\u00d5ES NECESS\u00c1RIAS DENTRO DO COMPONENTE ---\n    import os\n    import json\n    import numpy as np\n    import pandas as pd\n    import joblib\n    from xgboost import XGBRegressor\n    from sklearn.metrics import mean_squared_error, r2_score\n    # ---------------------------------------------------\n\n    try:\n        print(\"Iniciando o componente train_model...\")\n\n        # 1) l\u00ea dados\n        print(f\"Lendo X_train de: {X_train_csv.path}\")\n        X_train = pd.read_csv(X_train_csv.path)\n        print(f\"Lendo y_train de: {y_train_csv.path}\")\n        y_train = pd.read_csv(y_train_csv.path).values.ravel()\n        print(\"Dados de treino lidos com sucesso.\")\n\n        # 2) treina\n        print(\"Iniciando o treinamento do modelo XGBRegressor...\")\n        model = XGBRegressor(\n            n_estimators=n_estimators,\n            learning_rate=learning_rate,\n            max_depth=max_depth,\n            subsample=subsample,\n            colsample_bytree=colsample_bytree,\n            random_state=random_state,\n            n_jobs=-1,\n        )\n        model.fit(X_train, y_train)\n        print(\"Treinamento conclu\u00eddo.\")\n\n        # 3) salva modelo\n        model_save_path = model_output.path + \"/model.joblib\"\n\n        # Garante que o diret\u00f3rio de sa\u00edda exista antes de salvar\n        print(f\"Garantindo que o diret\u00f3rio de sa\u00edda exista: {model_output.path}\")\n        os.makedirs(model_output.path, exist_ok=True) # <-- CORRE\u00c7\u00c3O 1\n\n        print(f\"Salvando o modelo em: {model_save_path}\")\n        joblib.dump(model, model_save_path)\n        print(\"Modelo salvo com sucesso.\")\n\n        # 4) m\u00e9tricas simples no treino (s\u00f3 para tracking)\n        print(\"Calculando m\u00e9tricas de treino...\")\n        y_pred_tr = model.predict(X_train)\n        rmse_tr = float(np.sqrt(mean_squared_error(y_train, y_pred_tr)))\n        r2_tr = float(r2_score(y_train, y_pred_tr))\n\n        metrics_data = {\"rmse_train\": rmse_tr, \"r2_train\": r2_tr}\n        print(f\"M\u00e9tricas de treino: {metrics_data}\")\n\n        # Garante que o diret\u00f3rio para o arquivo de m\u00e9tricas exista\n        # Usa .path pois agora \u00e9 um Artefato\n        print(f\"Garantindo que o diret\u00f3rio de m\u00e9tricas exista: {os.path.dirname(train_metrics.path)}\")\n        os.makedirs(os.path.dirname(train_metrics.path), exist_ok=True)\n\n        # Usa .path pois agora \u00e9 um Artefato\n        with open(train_metrics.path, \"w\") as f:\n            json.dump(metrics_data, f, indent=4)\n\n        print(\"M\u00e9tricas de treino salvas. Componente train_model conclu\u00eddo.\")\n\n    except Exception as e:\n        print(f\"Erro no componente train_model: {e}\")\n        raise\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-train-val-split": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_val_split"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pandas' 'scikit-learn' 'gcsfs'  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_val_split(\n    X_csv: Input[Dataset],\n    y_csv: Input[Dataset],\n    X_train_csv: Output[Dataset],\n    X_val_csv: Output[Dataset],\n    y_train_csv: Output[Dataset],\n    y_val_csv: Output[Dataset],\n    test_size: float = 0.2,\n    random_state: int = 42,\n):\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n\n    print(f\"Lendo dados de entrada:\")\n    print(f\" - X: {X_csv.path}\")\n    print(f\" - y: {y_csv.path}\")\n\n    X = pd.read_csv(X_csv.path)\n    y = pd.read_csv(y_csv.path)\n\n    print(f\"Tamanho inicial: X={X.shape}, y={y.shape}\")\n\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=test_size, random_state=random_state\n    )\n\n    print(f\"Salvando artefatos de sa\u00edda...\")\n    X_train.to_csv(X_train_csv.path, index=False)\n    X_val.to_csv(X_val_csv.path, index=False)\n    y_train.to_csv(y_train_csv.path, index=False)\n    y_val.to_csv(y_val_csv.path, index=False)\n\n    print(f\"\u2705 Divis\u00e3o conclu\u00edda! Treino: {X_train.shape}, Valida\u00e7\u00e3o: {X_val.shape}\")\n\n"
          ],
          "image": "python:3.10"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "Pipeline com leitura, preprocessamento, split, treino, avalia\u00e7\u00e3o E REGISTRO",
    "name": "accident-risk-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "evaluate-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-evaluate-model"
          },
          "dependentTasks": [
            "train-model",
            "train-val-split"
          ],
          "inputs": {
            "artifacts": {
              "X_val_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "X_val_csv",
                  "producerTask": "train-val-split"
                }
              },
              "model_input": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model_output",
                  "producerTask": "train-model"
                }
              },
              "y_val_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "y_val_csv",
                  "producerTask": "train-val-split"
                }
              }
            }
          },
          "taskInfo": {
            "name": "evaluate-model"
          }
        },
        "load-train-data": {
          "cachingOptions": {},
          "componentRef": {
            "name": "comp-load-train-data"
          },
          "inputs": {
            "parameters": {
              "train_path": {
                "componentInputParameter": "train_path"
              }
            }
          },
          "taskInfo": {
            "name": "load-train-data"
          }
        },
        "preprocess-encode": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-preprocess-encode"
          },
          "dependentTasks": [
            "load-train-data"
          ],
          "inputs": {
            "artifacts": {
              "train_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_csv",
                  "producerTask": "load-train-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "preprocess-encode"
          }
        },
        "register-model-in-registry": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-register-model-in-registry"
          },
          "dependentTasks": [
            "evaluate-model",
            "train-model"
          ],
          "inputs": {
            "artifacts": {
              "eval_metrics": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "eval_metrics",
                  "producerTask": "evaluate-model"
                }
              },
              "model_input": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model_output",
                  "producerTask": "train-model"
                }
              }
            },
            "parameters": {
              "model_display_name": {
                "componentInputParameter": "model_name"
              },
              "project_id": {
                "componentInputParameter": "project_id"
              },
              "project_location": {
                "componentInputParameter": "project_location"
              }
            }
          },
          "taskInfo": {
            "name": "register-model-in-registry"
          }
        },
        "train-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-model"
          },
          "dependentTasks": [
            "train-val-split"
          ],
          "inputs": {
            "artifacts": {
              "X_train_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "X_train_csv",
                  "producerTask": "train-val-split"
                }
              },
              "y_train_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "y_train_csv",
                  "producerTask": "train-val-split"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-model"
          }
        },
        "train-val-split": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-val-split"
          },
          "dependentTasks": [
            "preprocess-encode"
          ],
          "inputs": {
            "artifacts": {
              "X_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "X_csv",
                  "producerTask": "preprocess-encode"
                }
              },
              "y_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "y_csv",
                  "producerTask": "preprocess-encode"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-val-split"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "model_name": {
          "defaultValue": "accident-risk-model",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "project_id": {
          "defaultValue": "vertexai-457414",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "project_location": {
          "defaultValue": "us-central1",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "train_path": {
          "defaultValue": "gs://road_accident/train.csv",
          "isOptional": true,
          "parameterType": "STRING"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.14.6"
}